{"qid": "ClassEval_57", "orig_input": "import numpy as np\n\n\nclass MetricsCalculator2:\n    \"\"\"\n    The class provides to calculate Mean Reciprocal Rank (MRR) and Mean Average Precision (MAP) based on input data, where MRR measures the ranking quality and MAP measures the average precision.\n    \"\"\"\n\n    def __init__(self):\n        pass\n\n    @staticmethod\n    def mrr(data):\n        \"\"\"\n        compute the MRR of the input data. MRR is a widely used evaluation index. It is the mean of reciprocal rank.\n        :param data: the data must be a tuple, list 0,1,eg.([1,0,...],5).  In each tuple (actual result,ground truth num),ground truth num is the total ground num.\n         ([1,0,...],5),\n        or list of tuple eg. [([1,0,1,...],5),([1,0,...],6),([0,0,...],5)].\n        1 stands for a correct answer, 0 stands for a wrong answer.\n        :return: if input data is list, return the recall of this list. if the input data is list of list, return the\n        average recall on all list. The second return value is a list of precision for each input.\n        >>> MetricsCalculator2.mrr(([1, 0, 1, 0], 4))\n        >>> MetricsCalculator2.mrr([([1, 0, 1, 0], 4), ([0, 1, 0, 1], 4)])\n        1.0, [1.0]\n        0.75, [1.0, 0.5]\n        \"\"\"\n\n\n    @staticmethod\n    def map(data):\n        \"\"\"\n        compute the MAP of the input data. MAP is a widely used evaluation index. It is the mean of AP (average precision).\n        :param data: the data must be a tuple, list 0,1,eg.([1,0,...],5).  In each tuple (actual result,ground truth num),ground truth num is the total ground num.\n         ([1,0,...],5),\n        or list of tuple eg. [([1,0,1,...],5),([1,0,...],6),([0,0,...],5)].\n        1 stands for a correct answer, 0 stands for a wrong answer.\n        :return: if input data is list, return the recall of this list. if the input data is list of list, return the\n        average recall on all list. The second return value is a list of precision for each input.\n        >>> MetricsCalculator2.map(([1, 0, 1, 0], 4))\n        >>> MetricsCalculator2.map([([1, 0, 1, 0], 4), ([0, 1, 0, 1], 4)])\n        0.41666666666666663, [0.41666666666666663]\n        0.3333333333333333, [0.41666666666666663, 0.25]\n        \"\"\"", "input": "import numpy as np\n\n\nclass MetricsCalculator2:\n    \"\"\"\n    The class provides to calculate Mean Reciprocal Rank (MRR) and Mean Average Precision (MAP) based on input data, where MRR measures the ranking quality and MAP measures the average precision.\n    \"\"\"\n\n    def __init__(self):\n        pass\n\n    @staticmethod\n    def mrr(data):\n        \"\"\"Calculates Mean Reciprocal Rank for input data, accepting single tuples or lists of tuples.\"\"\"\n\n\n    @staticmethod\n    def map(data):\n        \"\"\"Calculates Mean Average Precision for input data, returning MAP and precision list for each input.\"\"\"", "method_info": [{"method_name": "mrr", "method_description": "def mrr(data):\n        \"\"\"\n        compute the MRR of the input data. MRR is a widely used evaluation index. It is the mean of reciprocal rank.\n        :param data: the data must be a tuple, list 0,1,eg.([1,0,...],5).  In each tuple (actual result,ground truth num),ground truth num is the total ground num.\n         ([1,0,...],5),\n        or list of tuple eg. [([1,0,1,...],5),([1,0,...],6),([0,0,...],5)].\n        1 stands for a correct answer, 0 stands for a wrong answer.\n        :return: if input data is list, return the recall of this list. if the input data is list of list, return the\n        average recall on all list. The second return value is a list of precision for each input.\n        >>> MetricsCalculator2.mrr(([1, 0, 1, 0], 4))\n        >>> MetricsCalculator2.mrr([([1, 0, 1, 0], 4), ([0, 1, 0, 1], 4)])\n        1.0, [1.0]\n        0.75, [1.0, 0.5]\n        \"\"\"", "test_class": "MetricsCalculator2TestMrr", "test_code": "class MetricsCalculator2TestMrr(unittest.TestCase):\n    def test_mrr_1(self):\n        mc2 = MetricsCalculator2()\n        res1, res2 = MetricsCalculator2.mrr(([1, 0, 1, 0], 4))\n        self.assertEqual(res1, 1.0)\n        self.assertEqual(res2, [1.0])\n\n    def test_mrr_2(self):\n        res1, res2 = MetricsCalculator2.mrr(([0, 0, 0, 1], 4))\n        self.assertEqual(res1, 0.25)\n        self.assertEqual(res2, [0.25])\n\n    def test_mrr_3(self):\n        res1, res2 = MetricsCalculator2.mrr([([1, 0, 1, 0], 4), ([0, 1, 0, 1], 4)])\n        self.assertEqual(res1, 0.75)\n        self.assertEqual(res2, [1.0, 0.5])\n\n    def test_mrr_4(self):\n        res1, res2 = MetricsCalculator2.mrr([([1, 1, 1, 0], 4), ([0, 0, 0, 1], 4)])\n        self.assertEqual(res1, 0.625)\n        self.assertEqual(res2, [1.0, 0.25])\n\n    def test_mrr_5(self):\n        res1, res2 = MetricsCalculator2.mrr([([1, 0, 1, 1], 4), ([0, 1, 0, 0], 4)])\n        self.assertEqual(res1, 0.75)\n        self.assertEqual(res2, [1.0, 0.5])\n\n    def test_mrr_6(self):\n        try:\n            MetricsCalculator2.mrr(1)\n        except:\n            pass\n\n    def test_mrr_7(self):\n        res1, res2 = MetricsCalculator2.mrr([])\n        self.assertEqual(res1, 0.0)\n        self.assertEqual(res2, [0.0])\n\n    def test_mrr_8(self):\n        res1, res2 = MetricsCalculator2.mrr([([1, 0, 1, 1], 0), ([0, 1, 0, 0], 0)])\n        self.assertEqual(res1, 0.0)\n        self.assertEqual(res2, [0.0, 0.0])", "solution_code": "def mrr(data):\n        if type(data) != list and type(data) != tuple:\n            raise Exception(\"the input must be a tuple([0,...,1,...],int) or a iteration of list of tuple\")\n\n        if len(data) == 0:\n            return 0.0, [0.0]\n        if type(data) == tuple:\n            (sub_list, total_num) = data\n            sub_list = np.array(sub_list)\n            if total_num == 0:\n                return 0.0, [0.0]\n            else:\n                ranking_array = 1.0 / (np.array(list(range(len(sub_list)))) + 1)\n                mr_np = sub_list * ranking_array\n\n                mr = 0.0\n                for team in mr_np:\n                    if team > 0:\n                        mr = team\n                        break\n                return mr, [mr]\n\n        if type(data) == list:\n            separate_result = []\n            for (sub_list, total_num) in data:\n                sub_list = np.array(sub_list)\n\n                if total_num == 0:\n                    mr = 0.0\n                else:\n                    ranking_array = 1.0 / (np.array(list(range(len(sub_list)))) + 1)\n                    mr_np = sub_list * ranking_array\n\n                    mr = 0.0\n                    for team in mr_np:\n                        if team > 0:\n                            mr = team\n                            break\n\n                separate_result.append(mr)\n            return np.mean(separate_result), separate_result", "dependencies": {"Standalone": true, "lib_dependencies": [], "field_dependencies": [], "method_dependencies": []}}, {"method_name": "map", "method_description": "@staticmethod\n    def map(data):\n        \"\"\"\n        compute the MAP of the input data. MAP is a widely used evaluation index. It is the mean of AP (average precision).\n        :param data: the data must be a tuple, list 0,1,eg.([1,0,...],5).  In each tuple (actual result,ground truth num),ground truth num is the total ground num.\n         ([1,0,...],5),\n        or list of tuple eg. [([1,0,1,...],5),([1,0,...],6),([0,0,...],5)].\n        1 stands for a correct answer, 0 stands for a wrong answer.\n        :return: if input data is list, return the recall of this list. if the input data is list of list, return the\n        average recall on all list. The second return value is a list of precision for each input.\n        >>> MetricsCalculator2.map(([1, 0, 1, 0], 4))\n        >>> MetricsCalculator2.map([([1, 0, 1, 0], 4), ([0, 1, 0, 1], 4)])\n        0.41666666666666663, [0.41666666666666663]\n        0.3333333333333333, [0.41666666666666663, 0.25]\n        \"\"\"", "test_class": "MetricsCalculator2TestMap", "test_code": "class MetricsCalculator2TestMap(unittest.TestCase):\n    def test_map_1(self):\n        res1, res2 = MetricsCalculator2.map(([1, 0, 1, 0], 4))\n        self.assertEqual(res1, 0.41666666666666663)\n        self.assertEqual(res2, [0.41666666666666663])\n\n    def test_map_2(self):\n        res1, res2 = MetricsCalculator2.map(([0, 0, 0, 1], 4))\n        self.assertEqual(res1, 0.0625)\n        self.assertEqual(res2, [0.0625])\n\n    def test_map_3(self):\n        res1, res2 = MetricsCalculator2.map([([1, 0, 1, 0], 4), ([0, 1, 0, 1], 4)])\n        self.assertEqual(res1, 0.3333333333333333)\n        self.assertEqual(res2, [0.41666666666666663, 0.25])\n\n    def test_map_4(self):\n        res1, res2 = MetricsCalculator2.map([([1, 1, 1, 0], 4), ([0, 0, 0, 1], 4)])\n        self.assertEqual(res1, 0.40625)\n        self.assertEqual(res2, [0.75, 0.0625])\n\n    def test_map_5(self):\n        res1, res2 = MetricsCalculator2.map([([1, 0, 1, 1], 4), ([0, 1, 0, 0], 4)])\n        self.assertEqual(res1, 0.3645833333333333)\n        self.assertEqual(res2, [0.6041666666666666, 0.125])\n\n    def test_map_6(self):\n        try:\n            MetricsCalculator2.map(1)\n        except:\n            pass\n\n    def test_map_7(self):\n        res1, res2 = MetricsCalculator2.map([])\n        self.assertEqual(res1, 0.0)\n        self.assertEqual(res2, [0.0])\n\n    def test_map_8(self):\n        res1, res2 = MetricsCalculator2.map([([1, 0, 1, 1], 0), ([0, 1, 0, 0], 0)])\n        self.assertEqual(res1, 0.0)\n        self.assertEqual(res2, [0.0, 0.0])", "solution_code": "@staticmethod\n    def map(data):\n        if type(data) != list and type(data) != tuple:\n            raise Exception(\"the input must be a tuple([0,...,1,...],int) or a iteration of list of tuple\")\n\n        if len(data) == 0:\n            return 0.0, [0.0]\n        if type(data) == tuple:\n            (sub_list, total_num) = data\n            sub_list = np.array(sub_list)\n            if total_num == 0:\n                return 0.0, [0.0]\n            else:\n                ranking_array = 1.0 / (np.array(list(range(len(sub_list)))) + 1)\n\n                right_ranking_list = []\n                count = 1\n                for t in sub_list:\n                    if t == 0:\n                        right_ranking_list.append(0)\n                    else:\n                        right_ranking_list.append(count)\n                        count += 1\n\n                ap = np.sum(np.array(right_ranking_list) * ranking_array) / total_num\n                return ap, [ap]\n\n        if type(data) == list:\n            separate_result = []\n            for (sub_list, total_num) in data:\n                sub_list = np.array(sub_list)\n\n                if total_num == 0:\n                    ap = 0.0\n                else:\n                    ranking_array = 1.0 / (np.array(list(range(len(sub_list)))) + 1)\n\n                    right_ranking_list = []\n                    count = 1\n                    for t in sub_list:\n                        if t == 0:\n                            right_ranking_list.append(0)\n                        else:\n                            right_ranking_list.append(count)\n                            count += 1\n\n                    ap = np.sum(np.array(right_ranking_list) * ranking_array) / total_num\n\n                separate_result.append(ap)\n            return np.mean(separate_result), separate_result", "dependencies": {"Standalone": true, "lib_dependencies": [], "field_dependencies": [], "method_dependencies": []}}], "test_cases": "import unittest\n\n\nclass MetricsCalculator2TestMrr(unittest.TestCase):\n    def test_mrr_1(self):\n        mc2 = MetricsCalculator2()\n        res1, res2 = MetricsCalculator2.mrr(([1, 0, 1, 0], 4))\n        self.assertEqual(res1, 1.0)\n        self.assertEqual(res2, [1.0])\n\n    def test_mrr_2(self):\n        res1, res2 = MetricsCalculator2.mrr(([0, 0, 0, 1], 4))\n        self.assertEqual(res1, 0.25)\n        self.assertEqual(res2, [0.25])\n\n    def test_mrr_3(self):\n        res1, res2 = MetricsCalculator2.mrr([([1, 0, 1, 0], 4), ([0, 1, 0, 1], 4)])\n        self.assertEqual(res1, 0.75)\n        self.assertEqual(res2, [1.0, 0.5])\n\n    def test_mrr_4(self):\n        res1, res2 = MetricsCalculator2.mrr([([1, 1, 1, 0], 4), ([0, 0, 0, 1], 4)])\n        self.assertEqual(res1, 0.625)\n        self.assertEqual(res2, [1.0, 0.25])\n\n    def test_mrr_5(self):\n        res1, res2 = MetricsCalculator2.mrr([([1, 0, 1, 1], 4), ([0, 1, 0, 0], 4)])\n        self.assertEqual(res1, 0.75)\n        self.assertEqual(res2, [1.0, 0.5])\n\n    def test_mrr_6(self):\n        try:\n            MetricsCalculator2.mrr(1)\n        except:\n            pass\n\n    def test_mrr_7(self):\n        res1, res2 = MetricsCalculator2.mrr([])\n        self.assertEqual(res1, 0.0)\n        self.assertEqual(res2, [0.0])\n\n    def test_mrr_8(self):\n        res1, res2 = MetricsCalculator2.mrr([([1, 0, 1, 1], 0), ([0, 1, 0, 0], 0)])\n        self.assertEqual(res1, 0.0)\n        self.assertEqual(res2, [0.0, 0.0])\n\n\nclass MetricsCalculator2TestMap(unittest.TestCase):\n    def test_map_1(self):\n        res1, res2 = MetricsCalculator2.map(([1, 0, 1, 0], 4))\n        self.assertEqual(res1, 0.41666666666666663)\n        self.assertEqual(res2, [0.41666666666666663])\n\n    def test_map_2(self):\n        res1, res2 = MetricsCalculator2.map(([0, 0, 0, 1], 4))\n        self.assertEqual(res1, 0.0625)\n        self.assertEqual(res2, [0.0625])\n\n    def test_map_3(self):\n        res1, res2 = MetricsCalculator2.map([([1, 0, 1, 0], 4), ([0, 1, 0, 1], 4)])\n        self.assertEqual(res1, 0.3333333333333333)\n        self.assertEqual(res2, [0.41666666666666663, 0.25])\n\n    def test_map_4(self):\n        res1, res2 = MetricsCalculator2.map([([1, 1, 1, 0], 4), ([0, 0, 0, 1], 4)])\n        self.assertEqual(res1, 0.40625)\n        self.assertEqual(res2, [0.75, 0.0625])\n\n    def test_map_5(self):\n        res1, res2 = MetricsCalculator2.map([([1, 0, 1, 1], 4), ([0, 1, 0, 0], 4)])\n        self.assertEqual(res1, 0.3645833333333333)\n        self.assertEqual(res2, [0.6041666666666666, 0.125])\n\n    def test_map_6(self):\n        try:\n            MetricsCalculator2.map(1)\n        except:\n            pass\n\n    def test_map_7(self):\n        res1, res2 = MetricsCalculator2.map([])\n        self.assertEqual(res1, 0.0)\n        self.assertEqual(res2, [0.0])\n\n    def test_map_8(self):\n        res1, res2 = MetricsCalculator2.map([([1, 0, 1, 1], 0), ([0, 1, 0, 0], 0)])\n        self.assertEqual(res1, 0.0)\n        self.assertEqual(res2, [0.0, 0.0])\n\n\nclass MetricsCalculator2Test(unittest.TestCase):\n    def test_metricscalculator2_1(self):\n        res1, res2 = MetricsCalculator2.mrr(([1, 0, 1, 0], 4))\n        self.assertEqual(res1, 1.0)\n        self.assertEqual(res2, [1.0])\n\n    def test_metricscalculator2_2(self):\n        res1, res2 = MetricsCalculator2.mrr([([1, 0, 1, 0], 4), ([0, 1, 0, 1], 4)])\n        self.assertEqual(res1, 0.75)\n        self.assertEqual(res2, [1.0, 0.5])\n\n    def test_metricscalculator2_3(self):\n        res1, res2 = MetricsCalculator2.map(([1, 0, 1, 0], 4))\n        self.assertEqual(res1, 0.41666666666666663)\n        self.assertEqual(res2, [0.41666666666666663])\n\n    def test_metricscalculator2_4(self):\n        res1, res2 = MetricsCalculator2.map([([1, 0, 1, 0], 4), ([0, 1, 0, 1], 4)])\n        self.assertEqual(res1, 0.3333333333333333)\n        self.assertEqual(res2, [0.41666666666666663, 0.25])", "solutions": ["import numpy as np\n\n\nclass MetricsCalculator2:\n    def __init__(self):\n        pass\n\n    @staticmethod\n    def mrr(data):\n        if type(data) != list and type(data) != tuple:\n            raise Exception(\"the input must be a tuple([0,...,1,...],int) or a iteration of list of tuple\")\n\n        if len(data) == 0:\n            return 0.0, [0.0]\n        if type(data) == tuple:\n            (sub_list, total_num) = data\n            sub_list = np.array(sub_list)\n            if total_num == 0:\n                return 0.0, [0.0]\n            else:\n                ranking_array = 1.0 / (np.array(list(range(len(sub_list)))) + 1)\n                mr_np = sub_list * ranking_array\n\n                mr = 0.0\n                for team in mr_np:\n                    if team > 0:\n                        mr = team\n                        break\n                return mr, [mr]\n\n        if type(data) == list:\n            separate_result = []\n            for (sub_list, total_num) in data:\n                sub_list = np.array(sub_list)\n\n                if total_num == 0:\n                    mr = 0.0\n                else:\n                    ranking_array = 1.0 / (np.array(list(range(len(sub_list)))) + 1)\n                    mr_np = sub_list * ranking_array\n\n                    mr = 0.0\n                    for team in mr_np:\n                        if team > 0:\n                            mr = team\n                            break\n\n                separate_result.append(mr)\n            return np.mean(separate_result), separate_result\n\n    @staticmethod\n    def map(data):\n        if type(data) != list and type(data) != tuple:\n            raise Exception(\"the input must be a tuple([0,...,1,...],int) or a iteration of list of tuple\")\n\n        if len(data) == 0:\n            return 0.0, [0.0]\n        if type(data) == tuple:\n            (sub_list, total_num) = data\n            sub_list = np.array(sub_list)\n            if total_num == 0:\n                return 0.0, [0.0]\n            else:\n                ranking_array = 1.0 / (np.array(list(range(len(sub_list)))) + 1)\n\n                right_ranking_list = []\n                count = 1\n                for t in sub_list:\n                    if t == 0:\n                        right_ranking_list.append(0)\n                    else:\n                        right_ranking_list.append(count)\n                        count += 1\n\n                ap = np.sum(np.array(right_ranking_list) * ranking_array) / total_num\n                return ap, [ap]\n\n        if type(data) == list:\n            separate_result = []\n            for (sub_list, total_num) in data:\n                sub_list = np.array(sub_list)\n\n                if total_num == 0:\n                    ap = 0.0\n                else:\n                    ranking_array = 1.0 / (np.array(list(range(len(sub_list)))) + 1)\n\n                    right_ranking_list = []\n                    count = 1\n                    for t in sub_list:\n                        if t == 0:\n                            right_ranking_list.append(0)\n                        else:\n                            right_ranking_list.append(count)\n                            count += 1\n\n                    ap = np.sum(np.array(right_ranking_list) * ranking_array) / total_num\n\n                separate_result.append(ap)\n            return np.mean(separate_result), separate_result"], "task": "class_eval", "split": "test", "transformation_type": "func_summary", "import_statement": ["import numpy as np"], "test_classes": ["MetricsCalculator2TestMrr", "MetricsCalculator2TestMap", "MetricsCalculator2Test"]}